{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "600df4b0-3196-402b-9929-42068b488f29",
   "metadata": {},
   "source": [
    "**Part 3a: Chain of Thought (CoT)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c048e771-6cac-4a1a-8f47-df88b227f271",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your Groq API Key:  ········\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "%pip install python-dotenv --upgrade --quiet langchain langchain-groq\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "if \"GROQ_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your Groq API Key: \")\n",
    "\n",
    "# Using Llama3.1-8b (Small/Fast) to demonstrate logic failures\n",
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25890e68-5c58-4f7e-a3cf-28be9bdf24bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STANDARD (Llama3.1-8b) ---\n",
      "To find out how many tennis balls Roger has now, we need to add the initial number of tennis balls he had (5) to the number of tennis balls he bought (2 cans * 3 tennis balls per can).\n",
      "\n",
      "2 cans * 3 tennis balls per can = 6 tennis balls\n",
      "\n",
      "Now, let's add the initial number of tennis balls (5) to the number of tennis balls he bought (6):\n",
      "\n",
      "5 + 6 = 11\n",
      "\n",
      "So, Roger now has 11 tennis balls.\n"
     ]
    }
   ],
   "source": [
    "question = \"Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many does he have now?\"\n",
    "\n",
    "# 1. Standard Prompt (Direct Answer)\n",
    "prompt_standard = f\"Answer this question: {question}\"\n",
    "print(\"--- STANDARD (Llama3.1-8b) ---\")\n",
    "print(llm.invoke(prompt_standard).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d01a414f-032e-4949-b83a-5c865af97d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Chain of Thought (Llama3.1-8b) ---\n",
      "To find out how many tennis balls Roger has now, we need to follow these steps:\n",
      "\n",
      "1. Roger already has 5 tennis balls.\n",
      "2. He buys 2 more cans of tennis balls. Each can has 3 tennis balls, so he buys 2 x 3 = 6 more tennis balls.\n",
      "3. Now, we add the tennis balls he already had (5) to the new tennis balls he bought (6). 5 + 6 = 11\n",
      "\n",
      "So, Roger now has 11 tennis balls.\n"
     ]
    }
   ],
   "source": [
    "# 2. CoT Prompt (Magic Phrase)\n",
    "prompt_cot = f\"Answer this question. Let's think step by step. {question}\"\n",
    "\n",
    "print(\"--- Chain of Thought (Llama3.1-8b) ---\")\n",
    "print(llm.invoke(prompt_cot).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ec63e1-e266-4f91-953a-e391fe580460",
   "metadata": {},
   "source": [
    "**Part 3b: Tree of Thoughts (ToT) & Graph of Thoughts (GoT)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98067af7-d4da-4b12-b3a1-4d7df424ba2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv --upgrade --quiet langchain langchain-groq\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "if \"GROQ_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your Groq API Key: \")\n",
    "\n",
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0.7) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2fb100-4cfa-438f-838e-bd346a5cf350",
   "metadata": {},
   "source": [
    "**TOT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81096596-a99c-40a0-97d2-beb8f65d5d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tree of Thoughts (ToT) Result ---\n",
      "As a child psychologist, I would recommend Solution 3: \"Create a 'Veggie Face' on their Plate\" as the most sustainable approach to encouraging a 5-year-old to eat vegetables. Here's why:\n",
      "\n",
      "1. **Promotes engagement and participation**: This approach encourages the child to be an active participant in the mealtime process. By choosing the vegetables and arranging them in different ways, the child feels more invested in the meal and is more likely to be excited about eating it.\n",
      "2. **Develops problem-solving skills**: By creating a \"veggie face\" on their plate, the child is encouraged to think creatively and use problem-solving skills to arrange the vegetables in a way that looks like a face.\n",
      "3. **Fosters self-expression and autonomy**: This approach allows the child to express their creativity and have control over their mealtime experience. By choosing the vegetables and arranging them in different ways, the child feels more in charge and confident.\n",
      "4. **Encourages exploration and learning**: By using different colored vegetables to create features like eyes, a nose, and a mouth, the child is encouraged to explore and learn about the different types of vegetables and their colors.\n",
      "5. **Develops positive relationships with vegetables**: By making mealtime more enjoyable and interactive, this approach can help the child develop a positive relationship with vegetables and establish healthy eating habits.\n",
      "\n",
      "In contrast, while Solutions 1 and 2 may be effective in the short-term, they may ultimately rely on bribery or manipulation, which can be counterproductive in the long-term. Solution 1, \"Veggie Faces,\" may be seen as a one-time novelty, while Solution 2, \"Veggie Roulette,\" may create anxiety around trying new foods. In contrast, Solution 3 promotes a sustainable and long-term approach to encouraging healthy eating habits.\n",
      "\n",
      "Ultimately, as a child psychologist, I believe that the key to promoting healthy eating habits is to create an environment that is supportive, engaging, and empowering for the child. By encouraging self-expression, creativity, and problem-solving skills, we can help children develop a positive relationship with food and establish healthy eating habits that will last a lifetime.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "problem = \"How can I get my 5-year-old to eat vegetables?\"\n",
    "\n",
    "prompt_branch = ChatPromptTemplate.from_template(\n",
    "    \"Problem: {problem}. Give me one unique, creative solution. Solution {id}:\"\n",
    ")\n",
    "\n",
    "branches = RunnableParallel(\n",
    "    sol1=prompt_branch.partial(id=\"1\") | llm | StrOutputParser(),\n",
    "    sol2=prompt_branch.partial(id=\"2\") | llm | StrOutputParser(),\n",
    "    sol3=prompt_branch.partial(id=\"3\") | llm | StrOutputParser(),\n",
    ")\n",
    "\n",
    "prompt_judge = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    I have three proposed solutions for: '{problem}'\n",
    "    \n",
    "    1: {sol1}\n",
    "    2: {sol2}\n",
    "    3: {sol3}\n",
    "    \n",
    "    Act as a Child Psychologist. Pick the most sustainable one (not bribery) and explain why.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "tot_chain = (\n",
    "    RunnableParallel(problem=RunnableLambda(lambda x: x), branches=branches)\n",
    "    | (lambda x: {**x[\"branches\"], \"problem\": x[\"problem\"]}) \n",
    "    | prompt_judge\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"--- Tree of Thoughts (ToT) Result ---\")\n",
    "print(tot_chain.invoke(problem))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2942f3a7-88f2-491d-9226-fbc1980a18e8",
   "metadata": {},
   "source": [
    "**GOT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc322940-ae44-4d65-905d-cf4c80439fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Graph of Thoughts (GoT) Result ---\n",
      "In \"Echoes of Eternity,\" a brilliant but reclusive physicist, Emma, has created a revolutionary time machine that manipulates not just space, but also the very fabric of human emotions, allowing her to relive pivotal moments from her past with the love she never found - her high school sweetheart, Alex. However, as she continues to traverse time, she discovers that her actions are creating echoes of her own existence, manifesting as dark, twisted versions of herself who will stop at nothing to claim her place in the present. As Emma's timeline begins to unravel, she must navigate the blurred lines between reality and her own paranoia, all while facing an ancient, malevolent force that has been awakened by her meddling with the timeline - a force that feeds on human fear and is determined to trap Emma and her loved one in an eternal cycle of terror, forever reliving the same night they died in a tragic accident.\n"
     ]
    }
   ],
   "source": [
    "prompt_draft = ChatPromptTemplate.from_template(\n",
    "    \"Write a 1-sentence movie plot about: {topic}. Genre: {genre}.\"\n",
    ")\n",
    "\n",
    "drafts = RunnableParallel(\n",
    "    draft_scifi=prompt_draft.partial(genre=\"Sci-Fi\") | llm | StrOutputParser(),\n",
    "    draft_romance=prompt_draft.partial(genre=\"Romance\") | llm | StrOutputParser(),\n",
    "    draft_horror=prompt_draft.partial(genre=\"Horror\") | llm | StrOutputParser(),\n",
    ")\n",
    "\n",
    "prompt_combine = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    I have three movie ideas for the topic '{topic}':\n",
    "    1. Sci-Fi: {draft_scifi}\n",
    "    2. Romance: {draft_romance}\n",
    "    3. Horror: {draft_horror}\n",
    "    \n",
    "    Your task: Create a new Mega-Movie that combines the TECHNOLOGY of Sci-Fi, the PASSION of Romance, and the FEAR of Horror.\n",
    "    Write one paragraph.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# 3. The Chain\n",
    "got_chain = (\n",
    "    RunnableParallel(topic=RunnableLambda(lambda x: x), drafts=drafts)\n",
    "    | (lambda x: {**x[\"drafts\"], \"topic\": x[\"topic\"]}) \n",
    "    | prompt_combine\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"--- Graph of Thoughts (GoT) Result ---\")\n",
    "print(got_chain.invoke(\"Time Travel\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54285303-727d-47a2-9c13-32b434c5ff55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dd6860-9c80-437c-abc4-c657b797192b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
